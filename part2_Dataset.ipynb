{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dezero에서의 Dataset, DataLodaer\n",
    "---\n",
    "Daatset을 설정한 뒤에 DataLoder로 설정한 Dataset을 끌고 온다.\n",
    "\n",
    "Dataset 은 샘플과 정답(label)을 저장하고, DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감싼다.\n",
    "\n",
    "> PyTorch의 도메인 특화 라이브러리들은 (FashionMNIST와 같은) 미리 준비해둔(pre-loaded) 다양한 데이터셋을 제공합니다.    \n",
    "> 데이터셋은 torch.utils.data.Dataset 의 하위 클래스로 개별 데이터를 특정하는 함수가 구현되어 있습니다.    \n",
    "> 이러한 데이터셋은 모델을 만들어보고(prototype) 성능을 측정(benchmark)하는데 사용할 수 있습니다.    \n",
    "> 1. 비디오 데이터셋 - https://pytorch.org/vision/stable/datasets.html  \n",
    "> 2. 텍스트 데이터셋 - https://pytorch.org/text/stable/datasets.html  \n",
    "> 3. 오디오 데이터셋 - https://pytorch.org/audio/stable/datasets.html  \n",
    "\n",
    "\n",
    "Dataset은 왜 만들었을까?\n",
    "\n",
    "데이터가 100만개라면, 거대한 데이터를 하나의 ndarray 인스턴스로 처리하면 모든 원소를 한꺼번에 메모리에 올려야 한다. \n",
    "\n",
    "당연히 메모리는 부담스러운 상황\n",
    "\n",
    "그렇기 때문에 이러한 문제에 대응이 가능하도록 Dataset 클래스를 만들었다.\n",
    "\n",
    "\n",
    "### 2. Dezero의 Dataset(복습)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dataset: # Dezero의 Dataset\n",
    "    def __init__(self, train=True, transform=None, target_transform=None):\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if self.transform is None:\n",
    "            self.transform = lambda x: x\n",
    "        if self.target_transform is None:\n",
    "            self.target_transform = lambda x: x\n",
    "\n",
    "        self.data = None # 입력 데이터 보관\n",
    "        self.label = None # 레이블 보관\n",
    "        self.prepare()\n",
    "\n",
    "    def __getitem__(self, index): # 객체에 슬라이싱이 가능하게 하는 특수 메소드 \n",
    "        assert np.isscalar(index) # 만약에 받은 요소가 스칼라이면 실행\n",
    "        if self.label is None: # 레이블이 존재치 않는다면\n",
    "            return self.transform(self.data[index]), None # 값에 인덱싱해서 반환\n",
    "        else:\n",
    "            return self.transform(self.data[index]), self.target_transform(self.label[index])\n",
    "\n",
    "    def __len__(self): # 데이터셋 길이 반환\n",
    "        return len(self.data)\n",
    "\n",
    "    def prepare(self): # 유도 쿨래스에서 마저 정의해야 한다. \n",
    "        pass\n",
    "\n",
    "class Spiral(Dataset): # 이렇게 데이터셋에 각종 데이터를 가져올 수 있게끔 설정해 뒀을것이다. \n",
    "    def prepare(self): # 이런식으로 인스턴스 변수인 data와 label데이터를 설정한다\n",
    "        self.data, self.label = get_spiral(self.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch또한 위와 비슷한 형상을 띄고 있을것이다. \n",
    "\n",
    "여기서 중요한 것은 데이터셋은 이미 다 정의가 되어있다는 것\n",
    "\n",
    "파이토치가 정해준 데이터셋을 그냥 이용하면 끝이다. 물론 튜닝을 할 수 있지만... 굳이?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. pytorch의 dataset\n",
    "---\n",
    "\n",
    "기본적으로 제공되는 틀인 Dataset이라는 클래스가 존재한다.\n",
    "\n",
    "이 클래스를 상속받고 \n",
    "\n",
    "__init__(self) : 필요한 변수들을 선언하는 메서드. input으로 오는 x와 y를 load 하거나, 파일목록을 load한다.\n",
    "\n",
    "__len__(self) : x나 y 는 길이를 넘겨주는 메서드.\n",
    "\n",
    "__getitem__(self, index) : index번째 데이터를 return 하는 메서드.\n",
    "\n",
    "들을 정의해주면 사용자 전용 Dataset 완성\n",
    "\n",
    "찾아보니 __len__ 메서드와 __getitiem__ 메서드를 지닌 어떤 것도 죄다 Dataset이 될 수 있다고 한다. (물론 오류에 대한 책임은 작성자가 지어야 한다.)\n",
    "\n",
    "> 사용자 정의 Dataset 클래스는 반드시 3개 함수를 구현해야 합니다: __init__, __len__, and __getitem__. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dezero의 Dataloader\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True, gpu=False):\n",
    "        self.dataset = dataset # 데이터 셋\n",
    "        self.batch_size = batch_size # 배치 크기\n",
    "        self.shuffle = shuffle # 에포크별로 셔플\n",
    "        self.data_size = len(dataset) # 데이터 사이즈 \n",
    "        self.max_iter = math.ceil(self.data_size / batch_size) # 최대 반복수\n",
    "        self.gpu = gpu # GPU\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.iteration = 0 # 반복자를 0으로 설정, 반복자는 데이터를 순차적으로 추출하는 기능을 제공한다.\n",
    "        if self.shuffle: # 만약에 셔플할 생각이거든\n",
    "            self.index = np.random.permutation(len(self.dataset)) # 그리 해주마\n",
    "        else: # 아니거든\n",
    "            self.index = np.arange(len(self.dataset)) #그냥 천천히 반환해라\n",
    "\n",
    "    def __iter__(self): # 클래스를 파이썬 반복자로 사용하기 위해 넣은 특수 메서드 \n",
    "        return self # 특수 메서드를 구현하고 자기 자신을 반환하도록 하는게 기본 문법.\n",
    "\n",
    "    def __next__(self): # 반복자에서 데이터를 순서대로 추출하기 위한 메서드\n",
    "        if self.iteration >= self.max_iter: #최대 반복자수보다 크거나 같다면\n",
    "            self.reset() # 아 ㅋㅋ 리셋해야지 뭐\n",
    "            raise StopIteration() # 다음 원소를 반환하도록 구현, 반환할 원소가 없으면 StopIteration()을 수행 \n",
    "\n",
    "        i, batch_size = self.iteration, self.batch_size\n",
    "        \n",
    "        batch_index = self.index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "\n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        x = xp.array([example[0] for example in batch])\n",
    "        t = xp.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "        return x, t # 데이터와 레이블을 반환\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset과는 달리 DataLoader는 그닥 사용자가 수정할 이유가 없다.\n",
    "\n",
    "DataLoader는 그저 Dataset를 기반으로 데이터를 꺼내는 것일뿐 그 이상의 기능을 할 이유가 없다.\n",
    "\n",
    "### 5. pytorch의 DataLoader\n",
    "---\n",
    "정의는 다음과 같다.\n",
    "\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None)\n",
    "\n",
    "\n",
    "parameter 설명\n",
    "\n",
    "1. dataset는 필수 입력 인자다.\n",
    "\n",
    "2. bath_size = 1 : 배치 크기이다.\n",
    "\n",
    "3. shuffle = False : 에포크별로 데이터셋을 뒤섞을건지 여부를 결정하는 것\n",
    "\n",
    "나머지는 많이 사용하지는 않는다. 그 외 설명은 다음 글을 참고하길 바란다.\n",
    "> DataLoader parameter 별 용도 : https://subinium.github.io/pytorch-dataloader/\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "``` py\n",
    "# DataLoader 사용 예제\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for x, t in train_dataloader:\n",
    "        print(x.shape, t.shape)\n",
    "\n",
    "        ...\n",
    "        \n",
    "```\n",
    "\n",
    "> https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader 데이터로더에 대한 자세한 파라미터 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('Pytorch_studing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d060f0828fc2b117241290c294bd7cf3e183c40a44f56e1a2627712ee0c7af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
