{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Oh-Taegyun/Pytorch_study/blob/main/part12_%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5%20%EC%A0%9C%EC%9E%91.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 코랩에서 작업할때 쓰는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1644683522.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    [![open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Oh-Taegyun/Pytorch_study/blob/main/part12_%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5%20%EC%A0%9C%EC%9E%91.ipynb)\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!ls /content/gdrive/MyDrive/hymenoptera_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms # 데이터 전처리를 위해 사용하는 라이브러리\n",
    "import torchvision.models as models # 다양한 파이토치 네트워크를 사용할 수 있도록 도와주는 패키지\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CPU인지 GPU인지 확인 후 device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지금 사용하는 device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #torch.cuda.is_available() GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "\n",
    "print(\"지금 사용하는 device :\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "data_path = '/content/gdrive/MyDrive/Deep_Learning/Transfer_Learning/catanddog/train'\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize([256, 256]), # 이미지의 크기를 조정 256 x 256 크기로 이미지 데이터 조정\n",
    "        transforms.RandomResizedCrop(224), # 이미지를 랜덤한 크기로 자름, 데이터의 확장 용도\n",
    "        transforms.RandomHorizontalFlip(), # 이미지를 랜덤하게 수평으로 뒤집는다\n",
    "        transforms.ToTensor() # 이미지 데이터를 텐서로 변환\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(data_path, transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "\n",
    "print(len(train_dataset)) # train_dataset에 포함된 데이터의 개수를 출력해라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 사전 훈련된 모델 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained = True)\n",
    "\n",
    "print(resnet18) # 여기서 출력된 fc가 Fully connected layer 로 완전연결 계층을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 내려받은 모델에 대한 추가 설정\n",
    "전이학습의 요점은 마지막 연결계층(Fully connected layer)만 학습하고 나머지 계층들은 학습이 안되도록 해야한다.  \n",
    "\n",
    "이는 내려받은 모델의 파라미터를 고정해주지 않으면, 전이 학습 도중에 파라미터가 학습이 되어버리는 대참사가 일어나게된다.\n",
    "\n",
    "따라서 파라미터에 대해서 학습이 되지 않도록 고정해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True) #resnet18을 그대로 불러와서\n",
    "\n",
    "for param in model.parameters(): # model.parameters()은 모델의 파라미터를 반환한다.\n",
    "    param.requires_grad = False # resnet18 모델에 더이상 역전파를 추적하지 않게 하여 모델의 합성곱층 가중치를 고정시킨다\n",
    "\n",
    "model.fc = nn.Linear(512,2) # 완전연결층을 이제 수정해주자. 분류되는 클래스의 숫자는 2개이므로 출력을 2로 만든다. 원래 출력이 (fc): Linear(in_features=512, out_features=1000, bias=True) 이었는데 \n",
    "# out_features=1000을 2로 바꿔주자\n",
    "# __setattr__의 특성 덕에 이런 문장으로 새로운 계층이 추가가 가능하다.\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True # 하지만 맨 마지막의 완전연결층은 계산 그래프를 형성하게 해서 역전파가 가능하게 함\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 학습을 위한 함수 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloaders, crtierion, optimizer, device, save_path, num_epochs=25):\n",
    "    since = time.time()\n",
    "    acc_history = []\n",
    "    loss_history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        running_loss = 0.0 # 손실 함수\n",
    "        running_corrects = 0 # 정답갯수\n",
    "\n",
    "        for inputs, labels in dataloaders:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # 기울기를 0으로 설정\n",
    "            outputs = model(inputs) # 순전파 학습\n",
    "            loss = crtierion(outputs, labels) # 손실 함수 구하기\n",
    "            _, preds = torch.max(outputs, 1) # 결과값 추출\n",
    "            loss.backward() # 역전파 실행 이때 requires_grad = True가 된 완전연결층만 역전파가 됨\n",
    "            optimizer.step() # 기울기 업데이트\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0) # 출력 결과와 레이블의 오차를 계산한 결과를 누적하여 저장한다\n",
    "            # loss.item() 으로 손실이 갖고 있는 스칼라 값을 가져올 수 있습니다.\n",
    "            running_corrects += torch.sum(preds == labels.data) # 출력 결과와 레이블이 동일한지 확인한 결과를 누적하여 저장\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss,epoch_acc)) # 참고) {:.소수점 자리수f} 포맷 코드 : {} 내에 실수의 소수점 자리수(.소수점 자리수f)를 지정해 줄 수 있음 소수점 4자리 까지 표시함\n",
    "        if epoch_acc > best_acc: # 만약에 어떤 에폭에서의 정확도가 최고 정확도보다 높을 경우 업데이트\n",
    "            best_acc = epoch_acc\n",
    "        \n",
    "        acc_history.append(epoch_acc.item())\n",
    "        loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since # 실행 시간 계산\n",
    "    print(f'실행 시간 : {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'이 모델의 최고 정확도: {best_acc:4f}') # 최고 정확도\n",
    "\n",
    "    torch.save(model.state_dict(),save_path) # 모든 에폭을 소진할 때 모델의 상태를 저장 \n",
    "\n",
    "    return acc_history, loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 파라미터 학습 결과를 옵티마지어에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = [] # 업데이트 할 파라미터를 저장하자\n",
    "for name, param in model.named_parameters(): # 모델 에서 파라미터를 꺼내 오자\n",
    "    if param.requires_grad == True: # 만일 역전파가 가능하도록 설정되어 있다면\n",
    "        params_to_update.append(param) # 파라미터 학습 결과를 저장하자 (에초당시 resnet18에선 마지막 완전연결층만 역전파가 가능하도록 했으니 마지막의 fc 파아미터만 출력되어야 한다)\n",
    "        print(\"\\t\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.fc.parameters()) # 옵티마이저는 Adam으로 설정한다. \n",
    "cost = torch.nn.CrossEntropyLoss() # 손실 함수 정의 무난하게 교차 엔트로피 오차로 설정\n",
    "criterion = nn.CrossEntropyLoss() # 손실함수지정\n",
    "save_data_path = '/content/gdrive/MyDrive/Deep_Learning/Learned_Parameters/part12_model_state_dict.pt'\n",
    "train_acc_hist, trian_loss_hist = train_model(model, train_loader, criterion, optimizer, device, save_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 모델 실전 테스트 전 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/gdrive/MyDrive/Deep_Learning/Transfer_Learning/catanddog/test'\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224), # 이미지의 크기를 조정 224 x 224 크기로 이미지 데이터 조정\n",
    "        transforms.CenterCrop(224), # 중앙을 기준으로 이미지를 자릅니다\n",
    "        transforms.ToTensor() # 이미지 데이터를 텐서로 변환\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(data_path, transform=transforms)\n",
    "\n",
    "test_loader = DataLoader(train_dataset,batch_size=32,num_workers=1,shuffle=True)\n",
    "\n",
    "print(len(test_dataset)) # train_dataset에 포함된 데이터의 개수를 출력해라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 테스트 데이터 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,dataloaders,device,save_path):\n",
    "    since = time.time()\n",
    "    acc_history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval() # 모델을 train에서 evaluation으로 변경 https://bluehorn07.github.io/2021/02/27/model-eval-and-train.html\n",
    "    model.to(device)\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloaders:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad(): # 자동미분을 사용하지 않음 (학습 목적이 아닌 테스트 목적)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
    "        print('Acc: {:.4f}'.format(epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc: # 만약에 어떤 에폭에서의 정확도가 최고 정확도보다 높을 경우 업데이트\n",
    "            best_acc = epoch_acc\n",
    "        \n",
    "        acc_history.append(epoch_acc.item())\n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since # 실행 시간 계산\n",
    "    print(f'Validation complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}') # 최고 정확도\n",
    "\n",
    "    return acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_hist= test_model(model, test_loader, device, save_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 모델의 훈련, 테스트 데이터의 정확도를 그래프로 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc_hist)\n",
    "plt.plot(val_acc_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. 오차 정보 그래프 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trian_loss_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. 예측 이미지 출력을 위한 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_convert(tensor):  \n",
    "    image=tensor.to(\"cpu\").clone().detach().numpy()  \n",
    "    image=image.transpose(1,2,0)  \n",
    "    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n",
    "    image=image.clip(0,1)  \n",
    "    return image  \n",
    "\n",
    "classes = {0:'cat', 1:'dog'} # 개와 고양이 두 개에 대한 레이블\n",
    "\n",
    "dataiter = iter(test_loader) # 테스트 데이터 로더의 반복자 반환\n",
    "images, labels = dataiter.next()  # 테스트 데이터 순차적으로 출력\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "output = model(images)  \n",
    "\n",
    "_,preds=torch.max(output,1) \n",
    "\n",
    "fig = plt.figure(figsize = (25,4))  \n",
    "\n",
    "for idx in np.arange(20):  \n",
    "    ax=fig.add_subplot(2,10,idx+1,xticks=[],yticks=[])  \n",
    "    plt.imshow(im_convert(images[idx]))  \n",
    "    ax.set_title(classes[labels[idx].item()])\n",
    "    ax.set_title(\"{}({})\".format(str(classes[preds[idx].item()]),str(classes[labels[idx].item()])),color=(\"green\" if preds[idx]==labels[idx] else \"red\"))  \n",
    "\n",
    "plt.show()  \n",
    "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('Pytorch_studing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d060f0828fc2b117241290c294bd7cf3e183c40a44f56e1a2627712ee0c7af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
