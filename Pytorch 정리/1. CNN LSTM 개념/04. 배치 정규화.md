
배치 정규화가 주목받는 이유는 다음과 같다. 
1. 학습을 빨리 진행할 수 있다. ( 학습 속도 개선 ) 
2. 초깃값에 크게 의존하지 않는다 
3. 오버피팅을 억제한다 ( 드롭아웃 등의 필요성 감소 ) 

![[1. CNN LSTM 개념/image/26.png]]

배치 정규화의 기본 아이디어는 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것이다. 그래서 아래 그림과 같이 데이터 분포를 정규화하는 " 배치 정규화 Batch Norm 계층 " 을 신경망에 삽입한다.

![[09.jpg]]

딥러닝 모델의 층이 깊어지면 각 층마다 값의 범위가 달라지는 경우가 있다. 이는 모델을 학습할 때 모든 데이터를 한 번에 이용하지 않고, 배치 단위로 나눠서 학습하게 되는데 배치 간의 데이터 분포가 달라서 생기는 일이다. 

배치 정규화는 이런 분포의 불균형을 해결하기 위한 기법이다. 배치 정규화층이 각 층에서의 값의 분포가 일정하도록 해준다. 

