
|함수|내용|제공 라이브러리|
|---|---|---|
|Conv2d(in, out, kernel, stride)|합성곱을 계산. in은 입력 채널 개수, out은 출력 채널 개수, kernel은 커널 크기, stride는 스트라이드를 정의. |torch.nn|
정말 많이 다뤄봤고 정말 많은 정보를 알기에... 필요한 함수만 짚고 넘어가자


### 1. 데이터 증강
---
데이터 증강에 관한 다양한 메서드

|함수|내용|제공 라이브러리|
|---|---|---|
|Compose([*tf])|전처리 함수 tf를 입력받아 차례대로 실행함|torchvision.transforms|
|RandomCrop(size)|이미지의 일부를 제거한 뒤 size 크기로 복원한다|torchvision.transforms|
|RandomHorizontalFlip(p)|p 확률로 이미지를 좌우대칭|torchvision.transforms|

``` python
import torchvision.transforms as T

transforms = Compose([
					  T.ToPILImage(),
					  RandomCrop((32, 32), padding=4)
					  RandomHorizontalFlip(p=0.5)
])

test_data = CIFAR10(
					root = "./",
					train = False,
					download = True,
					transform = transforms)
)
```


### 2. 이미지 정규화
---
이미지가 R,G,B로 이루어져 있을때, 너무 한쪽으로 치우쳐저 있다면 신경망이 학습이 어렵다.

데이터는 기본적으로 분포가 너무 치우쳐져 있으면 학습에 악영향을 미친다. 따라서 학습 전에 편향을 계산해 최대한 정규분포를 따르도록 하는 게 좋다. 이 과정을 **정규화** 라고 한다. 정규 분포를 가우스 분포라고도 한다. 

![[03.jpg]]

무슨 소린가 하면 

만약 자동차가 빨간색, 초록색, 파란색 자동차가 있다고 하자
그럼 빨간색 자동차는 R이 높게, 초록색 자동차는 G가 높게, 파란색 자동차는 B가 높게 각각 R,G,B값이 큰 쪽으로 나타날 것이다. 

그런걸 넣으면 학습이 잘 안된다고 한다.

|함수|내용|제공 라이브러리|
|---|---|---|
|Normalize(mean, std)|평균 mean, 표준편차 std를 갖는 정규분포가 되도록 정규화 실행|torchvision.transforms|

``` python
import torchvision.transforms as T

transforms = Compose([
		  T.ToPILImage(),
		  RandomCrop((32, 32), padding=4)
		  RandomHorizontalFlip(p=0.5),
		  T.ToTensor()
	      Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261)),
		  T.ToPILImage()
])
```


### 3. 풀링
---
다양한 풀링이 있지만 가장 많이 쓰이는 풀링만 적어둔다다

| 함수 | 내용 | 제공 라이브러리 |
| ---- | ---- | ---- |
| MaxPool2d(kernel, stride) | 최대 풀링을 실행 kernel은 커널 크기, stride는 커널이 이동하는 거리를 지정 | torch.nn |
1. 최대 풀링
 - 이미지 크기를 절반으로 줄이는 연산으로 합성곱을 통해 얻은 특징의 위치 정보를 의도적으로 없애 오버피팅을 피하는 기법이다. 
 - 커널을 이동하면서 커널 안의 최댓값만을 남기는 것으로, 중요한 특징의 값을 알 수 있다. 반면 위치는 알 수 없다. 



### 4. 신경망 끼리의 차이
---

| 함수      | 내용                                                                                                                                                                                                    |
| --------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| VGG       | 가장 기본이 되는 CNN. VGG 이전의 CNN은 커널 크기가 커서 학습해야 하는 가중치 수가 많았지만, VGG는 3x3 크기의 커널을 이용해서 가중치 개수를 줄일 수 있다                                                 |
| ResNet    | 입력 이미지와 특징 맵을 더하는 CNN. 층이 깊어질수록 역전파되는 오차가 작아지는 문제를 어느 정도 해결했습니다. 그로 인해 VGG와는 비교도 안 되는 깊이를 가졌다. CNN 모델 중에서 ResNet을 가장 많이 사용함 |
| Inception | 3x3 커널을 여러 번 중첩해 크기가 큰 커널을 근사했습니다. VGG보다 넓은 시야를 갖게 됐으며, 큰 크기의 커널보다 적은 수의 가중치로 비슷한 효과를 얻는다.                                                   |

VGG는 19층 이상으로 쌓으면 기울기가 소실되어서 의미가 없어짐, 반면 ResNet은 스킵커넥션을 이용해 기울기 소실 문제를 해결했기에 100층까지 쌓을 수 있다. 



