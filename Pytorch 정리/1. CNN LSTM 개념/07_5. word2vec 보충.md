
![[52.png]]

![[53.png|150]]

이 식은 w_(t-1)과 w_(t+1)이 일어난 후 w_t가 일어날 확률을 뜻한다. 그리고 w_(t-1)과 w_(t+1)이 주어졌을 때 w_t가 일어날 확률로 해석할 수 있죠 즉, CBOW는 위 식을 모델링 하고 있는 것이다.

여기서 문제의 정답은 ‘w_t가 발생’이므로 w_t에 해당하는 원소만 1이고 나머지는 0이 된다 (즉, w_t 이외의 일이 일어날 경우에 대해서는 해당 원핫 레이블의 요소는 0이 된다.) 따라서 다음 식을 유도해 낼 수 있다.

![[54.png|200]]

CBOW 모델의 손실 함수는 단순히 위 식에 log를 취한 다음 마이너스를 붙이면 된다.

![[56.png|250]]

CBOW 모델의 학습이 수행하는 일은 이 손실 함수의 값을 가능한 한 작게 만드는 것이다. 그리고 이때의 가중치 매개변수가 우리가 얻고자 하는 단어의 분산 표현인 것이다