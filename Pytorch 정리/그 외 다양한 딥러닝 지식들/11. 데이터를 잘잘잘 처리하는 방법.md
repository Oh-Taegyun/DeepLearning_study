### 1. 데이터 준비 과정에서..
---
![[Pasted image 20240403013725.png|400]]

과소적합과 과대적합의 줄다리기는 딥러닝의 영원한 해결 주제이다. 하지만, 여태껏 아무생각 없이 데이터를 가져다가 쓰기만 했지 내가 직접 딥러닝을 설계하고 데이터를 모아야 하는 상황에서는 냅다 가져다가 쓰는 것은 당연하게 바람직하지 않다. 그에 대한 정리법이다.


### 2. 잡음 섞인 훈련 데이터
---
![[Pasted image 20240403014038.png|500]]

쉽게 말해 노이즈가 낀 데이터들 당연하게 딥러닝이 이걸 세밀하게 처리하게 둬서는 안된다. 모델이 이런 이상치에 맞게 학습했다는 것은 어떠한 데이터의 특징을 잡아 처리하는게 아니라 그냥 답안지를 외웠다는 소리이다. 

(더 심한 애들은 레이블이 잘못된 경우인데 이건 특징을 학습했는데 갑자기 꼬여버린거라 진짜 큰일난다 조심해라)


### 3. 불확실한 특성
---
딥러닝의 장점은 사람도 모르는 특징을 잘 잡아서 학습하는 것이다. 하지만 여기에 너무 의존해서는 안된다. 문제에 불확실성과 모호성이 있다면 완벽하고 깔끔하게 레이블이 부여된 데이터라도 잡음이 생긴다. 

분류 작업에서 입력 특성 공간의 일부 영역이 동시에 여러 클래스에 연관된 경우(예를 들어서 바나나가 덜 익었는지 아닌지) 당연하게 딥러닝도 처리 못한다. 

아까 바나나의 예시를 들었는데 아예 초록색 바나나와 노란색 바나나만을 구분하는 거라면 문제가 없는데 초록색과 노란색 중간에 있는 경우가 골치 아파진단 것이다. **쉽게 말해 데이터의 레이블을 부여하는 사람마다 각기 다르게 부여할만한 상황을 피해야 한단것**


### 4. 드문 특성
---
딥러닝 모델에서의 드문 특성은 모델이 학습 과정에서 특정 패턴이나 관계를 과도하게 일반화하는 경우에 나타난다. 즉, 제한된 데이터로부터 너무 구체적인 결론을 도출하는 것이다. 예시로는 다음과 같다. 

- **언어 모델링과 편향**: 한 언어 모델이 주로 특정 지역의 뉴스 소스에서만 훈련되었다고 가정해 봅시다. 이 모델은 해당 지역의 사건, 문화, 심지어 방언에 대한 정보를 과도하게 반영할 수 있습니다. 예를 들어, 모델이 특정 지역에서만 사용되는 단어나 표현을 일반적인 언어 사용의 일부로 잘못 학습할 수 있습니다. 이 경우, 모델은 드문 특성(특정 지역적 용어 사용)을 너무 강하게 일반화하여, 다른 지역이나 맥락에서 사용될 때 잘못된 가정이나 추론을 할 수 있습니다.

- **이미지 인식과 배경의 오해**: 이미지 인식 시스템이 특정 객체를 인식할 때 배경 정보를 과도하게 사용하는 경우입니다. 예를 들어, 모델이 개를 주로 특정 배경(예: 잔디밭)에서만 보고 학습했다면, 다른 배경(예: 해변)에서 개를 인식하는 데 어려움을 겪을 수 있습니다. 이러한 경우, 드문 특성(특정한 배경에서의 객체)이 모델의 판단에 과도한 영향을 미치게 되며, 이는 일반화 능력을 저하시키고 특정 상황에서의 인식 오류로 이어질 수 있습니다.


### 5. 가짜 상관관계
---
가짜 상관관계 (Spurious Correlation)란 두 변수가 전혀 관계가 없는데 모델이 관계가 있다고 생각하는 경우이다. 

간단하게 mnist로 예시를 들어 보자

![[Pasted image 20240403014823.png|500]]

만약 내가 mnist에 랜덤한 노이즈를 부여해보도록 하겠다. 간단하게 백색 잡음을 넣어보자, 아무 의미가 없는 특성의 연결은 당연하게 데이터가 가진 기본 정보에 전혀 영향을 주지 않는다. 

근데 이렇게 할 경우 잡음과 숫자를 어떠한 연관이 있을거라 판단하고 결론을 내린 것이다. 데이터에 노이즈가 부여되면 안되는 이유중 하나, 잡음 특성은 필연적으로 과대적합을 유발하기 때문이다. (똑같은 모델로 잡음이 있는거랑 없는거랑 똑같은 에폭으로 실험해봐도 가짜 상관관계를 학습해서 정확도가 낮아지는거다.)

따라서 어떤 특성이 모델에 유익한지 또는 모델을 혼란스럽게 만드는지 확실하지 않다면 훈련 전에 특성 선택을 수행하는 것이 일반적이다. 


### 6. 특성 선택
---
여러 방법이 있겠지만, 가장 일반적인 방법은 가용한 각 특성에 대해 어떤 유용성 점수를 계산하는것이다. (근데 당연히 데이터가 유용한 범위 내에서 사용해야 하니까.... 당연한 말이다)

각 특성끼리 겹쳐질 경우, 상호 의존 정보를 파악해야 하는 것이 중요하다. 즉, 특성이 얼마나 유익한지 측정 후 일정 임계값을 넘긴 특성만 사용하는 것. 임계값보다 낮은 경우 특성끼리 유익하지 않다고 판단하는 것이다. 


### 7. 매니폴드 가설
---
[[12. 매니폴드 가설]] 참고



