### 1. 훈련, 검증, 테스트 세트
---
훈련, 검증, 테스트 세트로 나누는 이유는 간단하다. 

보통 하이퍼파라미터를 조정할때 우리는 검증 데이터를 쓴다. 이게 문제다. 하이퍼 파라미터를 사람이 조정해주는 것 또한 어찌보면 학습이라는 큰 범주에 들어간다. 즉, 검증 데이터의 정보들이 새어나간다는 것이다. 물론 한번의 반복으로는 어림도 없겠지만 그게 무수히 많이 발생된다면 문제가 꽤나 골치아파진다.

따라서 테스트 세트를 또 다시 나눠서 모델의 출시 전에 검증함으로써 이 모델이 적합한지 마지막으로 확인하는 것이다. (물론 테스트 세트도 밥먹듯이 테스트하면 정보 누설의 문제가 생기긴 한데 에초에 그 지경까지 갔으면 데이터의 문제가 많단 뜻이다)


### 1. 단순 홀드아웃 검증
---
![[Pasted image 20240403025127.png|500]]

데이터의 일정량을 테스트 데이터로 때어낸다. 그리고 학습한다. 

문제는 데이터부자면 문제가 없지만 데이터거지면 문제가 커진다. 안그래도 부족한 데이터를 또다시 나눠야 한다는게 참.. 

뭐 어찌저찌 데이터를 나눴다고 치자, 문제는 데이터를 나눈다는 것 자체가 데이터끼리 집단을 형성한다는 것인데, 데이터가 적은 상태에서 그런다면 각 집단마다 고유 특성을 가질 확률이 매우 크다.  따라서 이에 대한 해결책이 필요하다

### 2. K-겹 교차 검증
---
![[Pasted image 20240403025424.png]]
1. 이 방식에서는 데이터를 동일한 크기를 가진 K개의 분할로 나눔
2. 각 분할 i에 대해 남은 K -1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가 
3. 최종 점수는 이렇게 얻은 K개의 점수를 평균 
4. 이 방법은 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 됨 
5. 홀드아웃 검증처럼 이 방법은 모델의 튜닝에 별개의 검증 세트를 사용

이걸 좀 더 일반적으로 바꾸면 다음과 같이 업그레이드가 가능하다.

셔플링을 사용한 반복 K-겹 교차 검증 
1. 이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용 
2. 캐글 경연에서는 이 방법이 아주 크게 도움이 됨 
3. 이 방법은 K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞음 
4. 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 됨 
5. P * K개(P는 반복 횟수)의 모델을 훈련하고 평가하므로 비용이 매우 많이 듦

보통 K는 일반적으로 4 또는 5를 선택한다. 