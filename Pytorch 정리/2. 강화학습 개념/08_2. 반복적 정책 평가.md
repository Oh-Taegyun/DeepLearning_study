![[스크린샷 2024-05-18 154323.png|400]]

1. 상태 전이는 고정적
2. 무작위 정책 π

>1. 상태 가치 함수의 벨만 방정식
	- 현재 상태에서, 모든 정책을 고려했을 때, 기대되는 수익은 얼마일까요? (스타트 지점 설정)
>2. 행동 가치 함수의 벨만 방정식
	- 현재 상태에서, 딱 1가지의 행동만 고려했을 때, 기대되는 수익을 어떻게 될까요? (현재 상태에서 각 행동에 대한 기댓값을 얻을 수 있다. ) 

이라고 했었다. 즉, 스타트 지점 설정이 가능하는 기능 이외에도, "현재 상태"에 대해서 평가를 내릴 수 있다는 아이디어이다. 

### 1. 식 유도하기
---
![[Pasted image 20240519155103.png]]

이때, 초기값으로 V<sub>0</sub>(s) = 0이라고 설정하자, 이 경우 L1과 L2로 초기값이 2개이므로, 다음과 같이 나타낼 수 있다. V<sub>0</sub>(L1) = V<sub>0</sub>(L2) = 0

### 2. 계산하기
---
![[스크린샷 2024-05-18 155912.png|300]]

두 갈래로 나뉜다. 

![[Pasted image 20240519160212.png]]

같은 방법으로 V<sub>2</sub>=-0.5 를 얻을 수 있다.  따라서 가치 함수 1차 갱신은 다음과 같다. 

![[Pasted image 20240519161006.png|400]]

이러한 계산을 계속 반복계산하면 된다. 계산을 코드로 구현해보자

``` python
V = {'L1': 0.0, 'L2': 0.0}
new_V = V.copy() # V의 복사본 별개의 V를 복사

for _ in range(100):
	new_V['L1'] = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])
	new_V['L2'] = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])
	V = new_V.copy() # new_V을 또 복사해서 V에 전달 메모리가 꽉 찰듯..
	print(V)
```

대략 코드를 실행한다면 값은 `[-2.25, -2.75]`이다. 이는 실제 가치 함수 값과 동일하다. 

임계값을 설정해서 자동으로 갱신 횟수를 조절해보자

``` python
V = {'L1': 0.0, 'L2': 0.0}
new_V = V.copy()
cnt = 0  # 갱신 횟수 기록

while True:
    new_V['L1'] = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])
    new_V['L2'] = 0.5 * (0 + 0.9 * V['L1']) + 0.5 * (-1 + 0.9 * V['L2'])

     # 갱신된 양의 최댓값
    delta = abs(new_V['L1'] - V['L1']) # L1일때의 이전값과 현재 값 차이
    delta = max(delta, abs(new_V['L2'] - V['L2'])) # L2일때의 이전값과 현재 값 차이중 가장 큰 값을 delta로 지정, 이는 두 원소 중 차이의 절대값 중 큰 값을 선택한다.  
    V = new_V.copy()
    cnt += 1

    if delta < 0.0001:  # 임계값 = 0.0001 가장 큰 차잇값이 임계점보다 낮아야함
        print(V)
        print('갱신 횟수:', cnt)
        break
```

기존의 갱신 방법은 딕셔너리를 이용해서 다음 그림과 같았다.
![[Pasted image 20240519163323.png|500]]

하지만 이 방법은 메모리 관점에서도 문제가 많고... 좀 느리다. 이를 다음 그림과 같이 바꿔보자

![[Pasted image 20240519163442.png|500]]

이 쪽이 메모리 관점에서도, 그리고 속도 면에서도 빠르다.

``` python
V = {'L1': 0.0, 'L2': 0.0}
cnt = 0

while True:
    t = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])
    delta = abs(t - V['L1'])
    V['L1'] = t

    t = 0.5 * (0 + 0.9 * V['L1']) + 0.5 * (-1 + 0.9 * V['L2'])
    delta = max(delta, abs(t - V['L2']))
    V['L2'] = t

    cnt += 1
    if delta < 0.0001:
        print(V)
        print('갱신 횟수:', cnt)
        break
```

이렇게 계속 반복적으로 계산하다보면, 결국 가치 함수의 값에 근접하게 될 것이다. 
