![[Pasted image 20240518154325.png]]

이전 2칸짜리 그리드 예제에서는 행동 정책이 결정적으로 움직인다고 했다. 하지만 이제는 50%의 확률로 무작위 정책을 바탕으로 행동한다고 하자. 

![[Pasted image 20240518154441.png|400]]

벨만 방정식은 다음과 같다. 

![[Pasted image 20240518153756.png]]

상태 전이는 결정적으로 된다고 하자. 따라서 다음과 같이 나타낼 수 있다 

![[Pasted image 20240518155055.png]]

이때 다음 환경 상태가 현재 상태(s)와 행동(a)에 따르지 않는 경우는 0이므로 절대적인 환경 상태 전이의 경우에서는 위 식을 다음과 같이 쓸 수 있다. 

![[Pasted image 20240518155622.png]]

이제 직접 구해보자

### 1. 상태 L1에 대한 벨만 방정식을 구해보자
---
![[Pasted image 20240518155942.png|300]]

할인율은 0.9라고 설정하면 다음과 같이 나타낼 수 있다.

![[Pasted image 20240518160422.png|400]]

상태 L1에 대한 벨만 방정식은 다음과 같다. 

![[Pasted image 20240518161542.png]]


### 2. 상태 L2에 대한 벨만 방정식을 구해보자
---
![[Pasted image 20240518161627.png|300]]

![[Pasted image 20240518162029.png]]

이제 두 식을 연립해서 풀어버린다면 다음과 같은 결과를 얻을 수 있다.

![[Pasted image 20240518162317.png]]

이는 무작위 정책의 상태 가치 함수이다. 상태 L1에서 무작위로 행동하면 앞으로 -2.25의 수익을 기대할 수 있다는 뜻이다. 무작위로 행동하면 벽에 붙이칠것이고 그에 따른 기대 수익이 -가 될 수 있다는 것이다. L1이 L2보다 높은 이유는 첫 번째 행동에서 사과를 얻을 확률이 50%이기 때문이다.

즉 현재 상태에서는 L1지점에 있는게 앞으로 얻을 기댓값이 -2.25란 것이다. 