정상(steady) 문제란 보상의 확률 분포가 변하지 않는 문제이다. 하지만 세상에서는 보상의 확률 분포가 매 번 바뀔 수 있다. 즉, 항상 똑같은 승률을 가지진 않는다는 것이다. 

### 1. 비정상 문제의 구현
---
``` python 
class NonStatBandit:
    def __init__(self, arms=10): 
        self.arms = arms
        self.rates = np.random.rand(arms) # 여러대의 머신의 고유 확률을 설정

    def play(self, arm):
        rate = self.rates[arm] # 임의의 머신을 선택했을 때 고유 확 반환
        self.rates += 0.1 * np.random.randn(self.arms)  # 노이즈 추가
        if rate > np.random.rand():
            return 1
        else:
            return 0
```

간단하게 플레이할때마다 고정된 확률이 아닌, 임의의 노이즈를 추가해서 확률이 조금씩 달라지게 해보겠다.

### 2. 비정상 문제를 풀기 위해서...
---
앞에서는 행동 가치를 다음과 같이 설정했다.

![[Pasted image 20240302002325 1.png|550]]

이는 다음과 같은 그래프로 그릴 수 있다. 이떄 `1/n`은 각 보상에 대한 가중치로 볼 수 있다. 

![[Pasted image 20240302002830 1.png]]

이는 모든 보상에 대해서 똑같은 가중치가 부여된다는 것이다. 새로 얻은 보상이든 오래전에 얻은 보상이든 모두 동등하게 취급된다는 뜻이다.

하지만 비정상 문제에서는 시간이 흐르면 환경(슬롯머신)이 변하기 때문에 과거 데이터(보상)의 중요도는 점점 낮아져야 한다. 반대로 새로 얻은 보상의 가중치는 점점 커져야 한다. 

따라서 위 식을 다음처럼 바꿔보자

![[Pasted image 20240302005456 1.png|300]]

가중치 `1/n`을 고정값 α(0<α<1)로 바꾼다면 다음처럼 그림이 그려진다.

![[Pasted image 20240302005633 1.png]]

이렇게 고정값 α(0<α<1)로 바꾼다면 오래전에 받은 보상일수록 기하급수적으로 낮아지는 것을 확인할 수 있다.

이처럼 바꾼 식은 지수적으로 감소하기 때문에 
![[Pasted image 20240302005919 1.png|650]]
이 식을 지수 이동 평균, 지수 가중 이동 평균이라고 한다. 


### 3. 비정상 문제 풀기
---
``` python
class NonStatBandit:
    def __init__(self, arms=10):
        self.arms = arms
        self.rates = np.random.rand(arms) # 여러대의 머신의 고유 확률을 설정

    def play(self, arm):
        rate = self.rates[arm] # 임의의 머신을 선택했을 때 코인 반환
        self.rates += 0.1 * np.random.randn(self.arms)  # 노이즈 추가
        if rate > np.random.rand():
            return 1
        else:
            return 0

class AlphaAgent:
    def __init__(self, epsilon, alpha, actions=10):
        self.epsilon = epsilon # ɛ 설정
        self.Qs = np.zeros(actions) # 각 슬롯머신의 가치 추정치
        self.alpha = alpha # 고정값 

    def update(self, action, reward):
        self.Qs[action] += (reward - self.Qs[action]) * self.alpha # 가치 추정치 업데이트

    def get_action(self):
        if np.random.rand() < self.epsilon: # 정해둔 ɛ보다 낮다면 
            return np.random.randint(0, len(self.Qs)) # 랜덤으로 선택후 경험치를 쌓는다
        return np.argmax(self.Qs) # 아니면 가장 좋은 머신을 선택해서 플레이
```

가중치 `1/n`과 고정값 α(0<α<1)을 사용했을때의 갱신을 비교하면 다음과 같다.

![[Pasted image 20240302010232 1.png]]

고정값으로 갱신했을때 보다 더 결과가 좋아짐을 확인할 수 있다. 


