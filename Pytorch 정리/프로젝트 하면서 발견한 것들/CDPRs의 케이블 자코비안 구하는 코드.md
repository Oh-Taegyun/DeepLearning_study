현재 연구실에서 6자유도 8케이블 CDPRs을 연구하고 있는데

다음과 같은 큰 오류를 발견했고 매우 조심해야 하는 부분이라 이렇게 적는다

먼저

![[./image/01.png]]

다음과 같이 역방향 운동학이 있다고 치자, X는 좌표값이고 결과는 각 케이블의 길이가 나온다.

![[./image/02.png]]

이것을 계산 그래프를 활용해서 자코비안을 계산하자고 했다.

그런데 나는 소스코드를 이렇게 짰다

``` python
def f_i(Pulley, End_Effector_coordinate, X):
	_, L_i = Inverse_Kinematics(Pulley, End_Effector_coordinate, X)
return L_i

def jacobian(Pulley, End_Effector_coordinate, X):
	L_i = f_i(Pulley, End_Effector_coordinate, X)
	L_i.backward(torch.ones_like(L_i))
return X.grad
```

계산 그래프를 이용해서 자코비안을 쉽게 구하겠다는 것은 매우 좋은 아이디어였다.

문제는 `jacobian` 함수에서 발생한다. `L_i.backward()`를 호출할 때, `L_i`는 텐서의 스칼라 요소가 아니므로 오류가 발생할 가능성이 높다. 

PyTorch에서 `.backward()`는 기본적으로 스칼라 값에 대해서만 작동한다. 여러 값을 가진 텐서에 대해서 `.backward()`를 호출하려면, 그래디언트의 모양이 `L_i`와 동일해야 한다. 나는 이 점을 이용했다고 생각했지만 망했다. 

`f_i` 함수는 `L_i`를 반환하는데, 이 값은 단순히 길이를 나타내는 스칼라 값의 배열이다. 즉, 이 함수는 `X`에 대한 벡터 함수가 아니다. 따라서, `jacobian` 함수는 `X`의 각 요소에 대한 `L_i`의 편미분을 계산하는 것이 아니라, 단순히 길이에 대한 변화를 계산한다. 결과적으로, 이 접근 방식은 예상한 바와 같은 자코비안 행렬을 생성하지 않을 것이다.

올바른 접근 방식은 `f_i` 함수가 `X`에 대한 벡터-벡터 함수가 되도록 하는 것입니다. 즉, 이 함수는 `X`의 각 변화에 대해 `L_i`의 각 요소가 어떻게 변하는지를 설명하는 함수가 되어야 합니다. 그런 다음, 이 함수에 대해 자코비안을 계산할 수 있습니다.

개선된 방법으로 `jacobian` 함수를 다시 작성하려면, 먼저 `f_i` 함수가 `X`의 각 요소에 대한 `L_i`의 변화를 어떻게 계산하는지 정의해야 합니다. 이를 위해서는 `X`에 대한 `f_i`의 출력이 벡터가 되도록 함수를 수정하고, 그에 따라 자코비안을 계산해야 합니다.